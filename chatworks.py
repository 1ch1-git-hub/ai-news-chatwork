#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
chatworks.py - SESæ¥­ç•Œå‘ã‘å…ˆç«¯æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰é…ä¿¡ç‰ˆ

æ¯é€±æœˆæ›œæ—¥æœ9æ™‚ã«SESæ¥­ç•Œã§æ±‚ã‚ã‚‰ã‚Œã‚‹å…ˆç«¯æŠ€è¡“ï¼ˆAIãƒ»IoTãƒ»ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»DXï¼‰
é–¢é€£ã®è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ï¼‹ãƒªãƒ³ã‚¯ã‚’å–å¾—ã—ã€æŒ‡å®šã®ChatWorkãƒ«ãƒ¼ãƒ ã¸æŠ•ç¨¿ã™ã‚‹ã‚¹ã‚¯ãƒªãƒ—ãƒˆã€‚

é‡ç‚¹æŠ€è¡“é ˜åŸŸ:
- AIãƒ»æ©Ÿæ¢°å­¦ç¿’: ChatGPTã€ç”ŸæˆAIã€LLMç­‰ã®DXæ¨é€²ã®ä¸­æ ¸æŠ€è¡“
- IoT: ã‚»ãƒ³ã‚µãƒ¼ã€ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã€ç”£æ¥­IoTç­‰
- ã‚¯ãƒ©ã‚¦ãƒ‰: AWSã€Azureã€GCPã€Kubernetesç­‰ã®ã‚¯ãƒ©ã‚¦ãƒ‰ãƒã‚¤ãƒ†ã‚£ãƒ–æŠ€è¡“
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£: ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã€ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆã€è„†å¼±æ€§å¯¾ç­–ç­‰
- DX: ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€æ¥­å‹™åŠ¹ç‡åŒ–ã€è‡ªå‹•åŒ–ç­‰

äº‹å‰æº–å‚™:
    pip install requests beautifulsoup4[lxml]
"""

import sys
import logging
import requests
import os
from datetime import datetime
from bs4 import BeautifulSoup

# â€”â€”â€” ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã‚’å–å¾— â€”â€”â€”
CHATWORK_TOKEN   = os.environ.get("CHATWORK_TOKEN")
CHATWORK_ROOM_ID = os.environ.get("CHATWORK_ROOM_ID")
NEWS_LIMIT       = 8  # ğŸ”¥ SESæ¥­ç•Œå‘ã‘: å…ˆç«¯æŠ€è¡“5åˆ†é‡ã‹ã‚‰8ä»¶ã‚’å³é¸é…ä¿¡

# è¨­å®šãƒã‚§ãƒƒã‚¯
if not CHATWORK_TOKEN or not CHATWORK_ROOM_ID:
    logging.error("ç’°å¢ƒå¤‰æ•° CHATWORK_TOKEN ã¨ CHATWORK_ROOM_ID ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    sys.exit(1)

# ğŸ”¥ SESæ¥­ç•Œå‘ã‘: å…ˆç«¯æŠ€è¡“ç‰¹åŒ–ã®é«˜å“è³ªãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚½ãƒ¼ã‚¹
# ã‚«ãƒ†ã‚´ãƒªãƒ¼: AI, IoT, CLOUD, SECURITY, DX
FEED_URLS = {
    # Tier 1: ä¸»è¦ç·åˆãƒ‹ãƒ¥ãƒ¼ã‚¹ï¼ˆåŸºæœ¬æƒ…å ±åé›†ï¼‰
    "tier1": [
        "https://news.google.com/rss/search?q=AI+OR+äººå·¥çŸ¥èƒ½+OR+æ©Ÿæ¢°å­¦ç¿’&hl=ja&gl=JP&ceid=JP:ja",
        "https://news.yahoo.co.jp/rss/topics/it.xml",
        "https://www3.nhk.or.jp/rss/news/cat06.xml",  # NHK ç§‘å­¦ãƒ»æ–‡åŒ–
    ],
    
    # Tier 2: ITå°‚é–€ãƒ¡ãƒ‡ã‚£ã‚¢ï¼ˆæŠ€è¡“è©³ç´°ï¼‰
    "tier2": [
        "https://rss.itmedia.co.jp/rss/2.0/itmedia_aiplus.xml",
        "https://rss.itmedia.co.jp/rss/2.0/itmedia_news.xml",
        "https://japan.cnet.com/rss/index.rdf",
        "https://ascii.jp/rss.xml",
        "https://www.watch.impress.co.jp/data/rss/1.0/ipw/feed.rdf",
    ],
    
    # Tier 3: ãƒ“ã‚¸ãƒã‚¹ãƒ»åˆ†æç³»ï¼ˆæˆ¦ç•¥ãƒ»å¸‚å ´è¦–ç‚¹ï¼‰
    "tier3": [
        "https://www.nikkei.com/rss/",
        "https://toyokeizai.net/list/feed/rss",
        "https://diamond.jp/list/feed/rss",
        "https://newswitch.jp/rss/index.rdf",
    ],
    
    # Tier 4: æŠ€è¡“å°‚é–€ãƒ»é–‹ç™ºè€…å‘ã‘ï¼ˆæ·±ã„æŠ€è¡“æƒ…å ±ï¼‰
    "tier4": [
        "https://www.publickey1.jp/atom.xml",
        "https://xtech.nikkei.com/rss/index.rdf",
        "https://gihyo.jp/feed/rss2",
        "https://codezine.jp/rss/new/20/index.xml",
        "https://ainow.ai/feed/",
    ],
    
    # Tier 5: é–‹ç™ºã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ï¼ˆå®Ÿè·µãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ï¼‰
    "tier5": [
        "https://qiita.com/popular-items/feed",
        "https://zenn.dev/feed",
        "https://note.com/rss",
    ],
    
    # Tier 6: ä¼æ¥­ãƒ†ãƒƒã‚¯ãƒ–ãƒ­ã‚°ï¼ˆå®Ÿè£…ä¾‹ãƒ»äº‹ä¾‹ï¼‰
    "tier6": [
        "https://developers.cyberagent.co.jp/blog/feed/",
        "https://techblog.yahoo.co.jp/atom.xml",
        "https://engineering.mercari.com/blog/feed.xml",
        "https://developer.hatenastaff.com/rss",
    ]
}

# ğŸ†• è¿½åŠ ã‚«ãƒ†ã‚´ãƒªãƒ¼ç”¨ã®ãƒ•ã‚£ãƒ¼ãƒ‰ï¼ˆOffice/Excelã€Ciscoã€ãƒ“ã‚¸ãƒã‚¹ã‚¹ã‚­ãƒ«ã€è‡ªå·±å•“ç™ºï¼‰
ADDITIONAL_FEEDS = {
    # Microsoft Officeãƒ»Excelé–¢é€£
    "office": [
        "https://www.microsoft.com/en-us/microsoft-365/blog/feed/",
        "https://office-hack.com/feed/",  # Officeç³»æ—¥æœ¬èªãƒ–ãƒ­ã‚°
        "https://www.moug.net/rss.xml",   # Excelãƒ»AccessæŠ€è¡“æƒ…å ±
    ],
    
    # Ciscoãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é–¢é€£
    "cisco": [
        "https://blogs.cisco.com/rss",
        "https://www.cisco.com/c/en/us/about/press/news-rss.xml",
        "https://network.gihyo.jp/feed/rss2",  # ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŠ€è¡“æ—¥æœ¬èª
        "https://atmarkit.itmedia.co.jp/rss/rdf/ait.rdf",  # @IT ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯
    ],
    
    # ãƒ“ã‚¸ãƒã‚¹ãƒ»è‡ªå·±å•“ç™ºé–¢é€£
    "business_skills": [
        "https://diamond.jp/list/feed/rss",
        "https://toyokeizai.net/list/feed/rss",
        "https://www.lifehacker.jp/feed/index.xml",
        "https://studyhacker.net/feed",  # å­¦ç¿’åŠ¹ç‡åŒ–
    ]
}

REQUEST_HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    )
}

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)]
)

def get_source_name(url: str) -> str:
    """URLã‹ã‚‰æƒ…å ±æºã®åå‰ã‚’å–å¾—ï¼ˆãƒãƒ«ãƒã‚«ãƒ†ã‚´ãƒªãƒ¼å¯¾å¿œç‰ˆï¼‰"""
    source_mapping = {
        "news.google.com": "Google ãƒ‹ãƒ¥ãƒ¼ã‚¹",
        "news.yahoo.co.jp": "Yahoo! ãƒ‹ãƒ¥ãƒ¼ã‚¹",
        "www3.nhk.or.jp": "NHK",
        "itmedia.co.jp": "ITmedia",
        "japan.cnet.com": "CNET Japan",
        "ascii.jp": "ASCII.jp",
        "watch.impress.co.jp": "Impress Watch",
        "www.nikkei.com": "æ—¥æœ¬çµŒæ¸ˆæ–°è",
        "toyokeizai.net": "æ±æ´‹çµŒæ¸ˆ",
        "diamond.jp": "ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰",
        "newswitch.jp": "ãƒ‹ãƒ¥ãƒ¼ã‚¹ã‚¤ãƒƒãƒ",
        "publickey1.jp": "Publickey",
        "xtech.nikkei.com": "æ—¥çµŒã‚¯ãƒ­ã‚¹ãƒ†ãƒƒã‚¯",
        "gihyo.jp": "æŠ€è¡“è©•è«–ç¤¾",
        "codezine.jp": "CodeZine",
        "ainow.ai": "AINOW",
        "qiita.com": "Qiita",
        "zenn.dev": "Zenn",
        "note.com": "note",
        "developers.cyberagent.co.jp": "CyberAgent",
        "techblog.yahoo.co.jp": "Yahoo! JAPAN",
        "engineering.mercari.com": "ãƒ¡ãƒ«ã‚«ãƒª",
        "developer.hatenastaff.com": "ã¯ã¦ãª",
        # Office/Excelé–¢é€£
        "techcommunity.microsoft.com": "Microsoft Tech",
        "support.microsoft.com": "Microsoft Support",
        "microsoft.com": "Microsoft",
        "office-hack.com": "Office Hack",
        "moug.net": "MOUG",
        # Cisco/ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯é–¢é€£  
        "blogs.cisco.com": "Cisco Blogs",
        "learningnetwork.cisco.com": "Cisco Learning",
        "cisco.com": "Cisco",
        "network.gihyo.jp": "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æŠ€è©•",
        "atmarkit.itmedia.co.jp": "@IT",
        # ãƒ“ã‚¸ãƒã‚¹ãƒ»è‡ªå·±å•“ç™ºé–¢é€£
        "president.jp": "PRESIDENT",
        "newspicks.com": "NewsPicks",
        "lifehacker.jp": "ãƒ©ã‚¤ãƒ•ãƒãƒƒã‚«ãƒ¼",
        "studyhacker.net": "STUDY HACKER",
        "globis.jp": "ã‚°ãƒ­ãƒ¼ãƒ“ã‚¹",
    }
    
    for domain, name in source_mapping.items():
        if domain in url:
            return name
    return "ãã®ä»–"

def get_article_category(title: str) -> str:
    """è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’åˆ¤å®š"""
    title_lower = title.lower()
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰è¾æ›¸ï¼ˆSESæ¥­ç•Œã®å…ˆç«¯æŠ€è¡“é‡è¦–ï¼‰
    category_keywords = {
        "ai": [
            # AIåŸºæœ¬ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            "ai", "ï¼¡ï¼©", "äººå·¥çŸ¥èƒ½", "æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°",
            # ç”ŸæˆAIãƒ»LLM
            "ç”Ÿæˆai", "ç”Ÿæˆï¼¡ï¼©", "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«", "llm", "ç”Ÿæˆå‹ai", "ã‚¸ã‚§ãƒãƒ¬ãƒ¼ãƒ†ã‚£ãƒ–ai",
            # ä¸»è¦AIã‚µãƒ¼ãƒ“ã‚¹
            "chatgpt", "ãƒãƒ£ãƒƒãƒˆgpt", "gpt", "claude", "gemini", "bard", "copilot",
            "mistral", "llama", "palm", "dall-e", "midjourney", "stable diffusion",
            # AIæ´»ç”¨ãƒ»å°å…¥
            "aiæ´»ç”¨", "aiå°å…¥", "aiæˆ¦ç•¥", "aiã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³", "aié–‹ç™º", "aiå®Ÿè£…",
        ],
        
        "iot": [
            # IoTåŸºæœ¬ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            "iot", "ï¼©ï½ï¼´", "ãƒ¢ãƒã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ", "internet of things",
            # IoTæŠ€è¡“
            "ã‚»ãƒ³ã‚µãƒ¼", "ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒã‚¤ã‚¹", "ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", "edge computing",
            "m2m", "ç”£æ¥­iot", "iiot", "ã‚¹ãƒãƒ¼ãƒˆã‚·ãƒ†ã‚£", "ã‚³ãƒã‚¯ãƒ†ãƒƒãƒ‰", "æ¥ç¶š",
            # IoTæ´»ç”¨
            "iotæ´»ç”¨", "iotãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ", "iotã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "iotã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³",
            "ioté–‹ç™º", "ãƒ‡ãƒã‚¤ã‚¹ç®¡ç†", "ã‚»ãƒ³ã‚µãƒ¼ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯", "çµ„ã¿è¾¼ã¿",
        ],
        
        "cloud": [
            # ã‚¯ãƒ©ã‚¦ãƒ‰åŸºæœ¬
            "ã‚¯ãƒ©ã‚¦ãƒ‰", "cloud", "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", "cloud computing",
            # ä¸»è¦ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
            "aws", "amazon web services", "azure", "microsoft azure", "gcp", "google cloud",
            # ã‚¯ãƒ©ã‚¦ãƒ‰æŠ€è¡“
            "ã‚¯ãƒ©ã‚¦ãƒ‰ãƒã‚¤ãƒ†ã‚£ãƒ–", "ãƒãƒ«ãƒã‚¯ãƒ©ã‚¦ãƒ‰", "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰",
            "paas", "saas", "iaas", "faas", "serverless", "ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹",
            # ã‚³ãƒ³ãƒ†ãƒŠãƒ»ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            "kubernetes", "docker", "ã‚³ãƒ³ãƒ†ãƒŠ", "k8s", "container",
            # ã‚¯ãƒ©ã‚¦ãƒ‰æ´»ç”¨
            "ã‚¯ãƒ©ã‚¦ãƒ‰ç§»è¡Œ", "ã‚¯ãƒ©ã‚¦ãƒ‰å°å…¥", "ã‚¯ãƒ©ã‚¦ãƒ‰é‹ç”¨", "ã‚¯ãƒ©ã‚¦ãƒ‰æœ€é©åŒ–",
        ],
        
        "security": [
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£åŸºæœ¬
            "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "security", "ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "cybersecurity",
            "æƒ…å ±ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£",
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£æŠ€è¡“
            "ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆ", "zero trust", "vpn", "ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«", "firewall",
            "æš—å·åŒ–", "èªè¨¼", "å¤šè¦ç´ èªè¨¼", "mfa", "sso", "ã‚·ãƒ³ã‚°ãƒ«ã‚µã‚¤ãƒ³ã‚ªãƒ³",
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„…å¨ãƒ»å¯¾ç­–
            "è„†å¼±æ€§", "ã‚µã‚¤ãƒãƒ¼æ”»æ’ƒ", "ãƒãƒ«ã‚¦ã‚§ã‚¢", "ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢", "ã‚¦ã‚¤ãƒ«ã‚¹",
            "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é‹ç”¨", "ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå¯¾å¿œ", "ãƒšãƒãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ",
            # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç®¡ç†
            "ã‚¢ã‚¯ã‚»ã‚¹åˆ¶å¾¡", "æ¨©é™ç®¡ç†", "ãƒ­ã‚°ç›£è¦–", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»",
        ],
        
        "dx": [
            # DXåŸºæœ¬
            "dx", "ï¼¤ï¼¸", "ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³", "digital transformation",
            "ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–", "ãƒ‡ã‚¸ã‚¿ãƒ«æ¨é€²", "ãƒ‡ã‚¸ã‚¿ãƒ«ã‚·ãƒ•ãƒˆ", "itåŒ–",
            # DXé–¢é€£æŠ€è¡“
            "æ¥­å‹™åŠ¹ç‡åŒ–", "è‡ªå‹•åŒ–", "rpa", "ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼", "ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„",
            "ãƒ‡ãƒ¼ã‚¿æ´»ç”¨", "ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿", "ãƒ‡ãƒ¼ã‚¿åˆ†æ", "bi", "ã‚¢ãƒŠãƒªãƒ†ã‚£ã‚¯ã‚¹",
            # DXæ¨é€²
            "dxæ¨é€²", "dxæˆ¦ç•¥", "itå°å…¥", "ã‚·ã‚¹ãƒ†ãƒ åˆ·æ–°", "ãƒ¬ã‚¬ã‚·ãƒ¼",
        ]
    }
    
    # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãƒãƒƒãƒæ•°ã§ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’åˆ¤å®š
    category_scores = {}
    for category, keywords in category_keywords.items():
        score = sum(1 for keyword in keywords if keyword in title_lower)
        if score > 0:
            category_scores[category] = score
    
    if not category_scores:
        return "other"
    
    # æœ€é«˜ã‚¹ã‚³ã‚¢ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’è¿”ã™
    return max(category_scores.items(), key=lambda x: x[1])[0]

def fetch_multi_category_news(limit: int = NEWS_LIMIT) -> list[dict]:
    """SESæ¥­ç•Œå‘ã‘å…ˆç«¯æŠ€è¡“è¨˜äº‹ã‚’å–å¾—ï¼ˆAI + IoT + ã‚¯ãƒ©ã‚¦ãƒ‰ + ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ + DXï¼‰"""
    articles = []
    successful_feeds = 0
    failed_feeds = 0
    source_stats = {}  # ã‚½ãƒ¼ã‚¹åˆ¥è¨˜äº‹æ•°çµ±è¨ˆ
    
    # å…¨ã¦ã®Tierã‹ã‚‰ãƒ•ã‚£ãƒ¼ãƒ‰ã‚’å–å¾—
    all_feeds = []
    for tier_name, feeds in FEED_URLS.items():
        for url in feeds:
            all_feeds.append((url, tier_name, "ai_source"))
    
    # ADDITIONAL_FEEDSã‚‚è¿½åŠ 
    for category_name, feeds in ADDITIONAL_FEEDS.items():
        for url in feeds:
            all_feeds.append((url, category_name, "additional_source"))
    
    logging.info(f"å‡¦ç†å¯¾è±¡ãƒ•ã‚£ãƒ¼ãƒ‰æ•°: {len(all_feeds)}ä»¶")
    
    for url, category_or_tier, feed_type in all_feeds:
        try:
            logging.info(f"Fetching feed: {url} (Category/Tier: {category_or_tier}, Type: {feed_type})")
            resp = requests.get(url, headers=REQUEST_HEADERS, timeout=15, verify=True)
            resp.raise_for_status()
            successful_feeds += 1
        except Exception as e:
            logging.warning(f"ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—å¤±æ•— ({get_source_name(url)}): {e}")
            failed_feeds += 1
            continue

        try:
            soup = BeautifulSoup(resp.content, "xml")
            source_name = get_source_name(url)
            
            # ã‚½ãƒ¼ã‚¹åˆ¥çµ±è¨ˆã‚’åˆæœŸåŒ–
            if source_name not in source_stats:
                source_stats[source_name] = 0
            
            # RSS ã® item
            for item in soup.find_all("item"):
                title_elem = item.find("title")
                link_elem = item.find("link")
                
                if title_elem and link_elem:
                    title = title_elem.get_text(strip=True)
                    link = link_elem.get_text(strip=True)
                    
                    if title and link:
                        # è¨˜äº‹ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’åˆ¤å®š
                        article_category = get_article_category(title)
                        
                        articles.append({
                            "title": title,
                            "link": link,
                            "source": source_name,
                            "tier": category_or_tier if feed_type == "ai_source" else "additional",
                            "category": article_category,
                            "feed_type": feed_type
                        })
                        source_stats[source_name] += 1
            
            # Atom ã® entry
            for entry in soup.find_all("entry"):
                title_elem = entry.find("title")
                link_elem = entry.find("link", rel="alternate") or entry.find("link")
                
                if title_elem:
                    title = title_elem.get_text(strip=True)
                    link = ""
                    
                    if link_elem:
                        if link_elem.has_attr("href"):
                            link = link_elem["href"].strip()
                        else:
                            link = link_elem.get_text(strip=True)
                    
                    if title and link:
                        # è¨˜äº‹ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚’åˆ¤å®š
                        article_category = get_article_category(title)
                        
                        articles.append({
                            "title": title,
                            "link": link,
                            "source": source_name,
                            "tier": category_or_tier if feed_type == "ai_source" else "additional",
                            "category": article_category,
                            "feed_type": feed_type
                        })
                        source_stats[source_name] += 1
                        
        except Exception as e:
            logging.warning(f"ãƒ•ã‚£ãƒ¼ãƒ‰è§£æå¤±æ•— ({get_source_name(url)}): {e}")
    
    # ã‚½ãƒ¼ã‚¹çµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›
    logging.info(f"å–å¾—ã—ãŸå…¨è¨˜äº‹æ•°: {len(articles)}ä»¶")
    logging.info(f"ã‚½ãƒ¼ã‚¹åˆ¥è¨˜äº‹æ•°: {dict(sorted(source_stats.items(), key=lambda x: x[1], reverse=True))}")

    logging.info(f"ãƒ•ã‚£ãƒ¼ãƒ‰å–å¾—çµæœ: æˆåŠŸ {successful_feeds}ä»¶, å¤±æ•— {failed_feeds}ä»¶")

    # ğŸ”¥ æ”¹å–„: SESæ¥­ç•Œã§æ±‚ã‚ã‚‰ã‚Œã‚‹å…ˆç«¯æŠ€è¡“ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆAIã€IoTã€ã‚¯ãƒ©ã‚¦ãƒ‰ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼‰
    tech_keywords = [
        # AIãƒ»æ©Ÿæ¢°å­¦ç¿’ï¼ˆDXæ¨é€²ã®ä¸­æ ¸æŠ€è¡“ï¼‰
        "ai", "ï¼¡ï¼©", "äººå·¥çŸ¥èƒ½", "æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’", "ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°",
        "ç”Ÿæˆai", "ç”Ÿæˆï¼¡ï¼©", "å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«", "llm", "chatgpt", "claude", "gemini",
        "aiæ´»ç”¨", "aiå°å…¥", "aiæˆ¦ç•¥", "aiã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³", "dxai",
        
        # IoTï¼ˆãƒ¢ãƒã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆï¼‰
        "iot", "ï¼©ï½ï¼´", "ãƒ¢ãƒã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ", "ã‚»ãƒ³ã‚µãƒ¼", "ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒã‚¤ã‚¹",
        "ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", "m2m", "ç”£æ¥­iot", "ã‚¹ãƒãƒ¼ãƒˆã‚·ãƒ†ã‚£", "ã‚³ãƒã‚¯ãƒ†ãƒƒãƒ‰",
        "iotæ´»ç”¨", "iotãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ", "iotã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "iotã‚½ãƒªãƒ¥ãƒ¼ã‚·ãƒ§ãƒ³",
        
        # ã‚¯ãƒ©ã‚¦ãƒ‰ï¼ˆAWS, Azure, GCPï¼‰
        "ã‚¯ãƒ©ã‚¦ãƒ‰", "aws", "azure", "gcp", "google cloud", "ã‚¯ãƒ©ã‚¦ãƒ‰ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°",
        "ã‚¯ãƒ©ã‚¦ãƒ‰ãƒã‚¤ãƒ†ã‚£ãƒ–", "ãƒãƒ«ãƒã‚¯ãƒ©ã‚¦ãƒ‰", "ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰ã‚¯ãƒ©ã‚¦ãƒ‰", "paas", "saas", "iaas",
        "kubernetes", "docker", "ã‚³ãƒ³ãƒ†ãƒŠ", "ã‚µãƒ¼ãƒãƒ¼ãƒ¬ã‚¹", "ã‚¯ãƒ©ã‚¦ãƒ‰ç§»è¡Œ", "ã‚¯ãƒ©ã‚¦ãƒ‰å°å…¥",
        
        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼ˆã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ï¼‰
        "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ã‚µã‚¤ãƒãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "æƒ…å ±ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£",
        "ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆ", "vpn", "ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«", "æš—å·åŒ–", "èªè¨¼", "è„†å¼±æ€§",
        "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–", "ã‚µã‚¤ãƒãƒ¼æ”»æ’ƒ", "ãƒãƒ«ã‚¦ã‚§ã‚¢", "ãƒ©ãƒ³ã‚µãƒ ã‚¦ã‚§ã‚¢", "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£é‹ç”¨",
        
        # DXé–¢é€£ï¼ˆãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
        "dx", "ï¼¤ï¼¸", "ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³", "ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–", "ãƒ‡ã‚¸ã‚¿ãƒ«æ¨é€²"
    ]
    
    # ğŸ”¥ SESæ¥­ç•Œå‘ã‘: å…ˆç«¯æŠ€è¡“ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
    # å…¨ã¦ã®è¨˜äº‹ã‚’æ®‹ã™ï¼ˆ"other"ã‚‚å«ã‚€ï¼‰ã§ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒãƒ©ãƒ³ã‚¹ã‚’å‘ä¸Š
    filtered = articles

    # ğŸ”¥ SESæ¥­ç•Œå‘ã‘: å…ˆç«¯æŠ€è¡“é‡è¦–ã®ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°æ©Ÿèƒ½
    category_counts = {}  # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã®é¸æŠæ¸ˆã¿è¨˜äº‹æ•°ã‚’è¿½è·¡
    
    def calculate_multi_category_score(article):
        title_lower = article["title"].lower()
        source = article.get("source", "")
        tier = article.get("tier", "additional")
        category = article.get("category", "other")
        score = 0
        
        # ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°ãƒœãƒ¼ãƒŠã‚¹: å°‘ãªã„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®è¨˜äº‹ã«å¤§ããªãƒœãƒ¼ãƒŠã‚¹
        current_count = category_counts.get(category, 0)
        balance_bonus = max(0, 10 - (current_count * 3))  # åŒã˜ã‚«ãƒ†ã‚´ãƒªãƒ¼ãŒå¤šã„ã»ã©ã‚¹ã‚³ã‚¢æ¸›å°‘
        score += balance_bonus
        
        # Tierãƒœãƒ¼ãƒŠã‚¹ï¼ˆAIã‚½ãƒ¼ã‚¹ã®ã¿ï¼‰
        if tier != "additional":
            tier_bonus = {
                "tier1": 2, "tier2": 3, "tier3": 2,
                "tier4": 4, "tier5": 1, "tier6": 1
            }
            score += tier_bonus.get(tier, 1)
        else:
            score += 3  # è¿½åŠ ã‚½ãƒ¼ã‚¹ã®ãƒ™ãƒ¼ã‚¹ã‚¹ã‚³ã‚¢ã‚’ä¸Šã’ã‚‹
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ãƒœãƒ¼ãƒŠã‚¹ï¼ˆSESæ¥­ç•Œã®å…ˆç«¯æŠ€è¡“é‡è¦–ï¼‰
        category_bonus = {
            "ai": 8,              # AIæŠ€è¡“ã¯æœ€å„ªå…ˆ
            "iot": 7,             # IoTæŠ€è¡“ã‚‚é«˜å„ªå…ˆåº¦
            "cloud": 7,           # ã‚¯ãƒ©ã‚¦ãƒ‰æŠ€è¡“ã‚‚é«˜å„ªå…ˆåº¦
            "security": 8,        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¯æœ€å„ªå…ˆ
            "dx": 6,              # DXæ¨é€²ã‚‚é‡è¦
            "other": 2            # ãã®ä»–ã¯ä½å„ªå…ˆåº¦
        }
        score += category_bonus.get(category, 1)
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰é‡ã¿ä»˜ã‘ï¼ˆSESæ¥­ç•Œã®é«˜å˜ä¾¡æ¡ˆä»¶å‘ã‘ï¼‰
        if category == "ai":
            ultra_keywords = ["chatgpt", "claude", "gemini", "ç”Ÿæˆai", "llm"]
            high_keywords = ["aiæ´»ç”¨", "aiå°å…¥", "æ©Ÿæ¢°å­¦ç¿’", "æ·±å±¤å­¦ç¿’"]
            for kw in ultra_keywords:
                if kw in title_lower: score += 10
            for kw in high_keywords:
                if kw in title_lower: score += 7
                
        elif category == "iot":
            key_keywords = ["iot", "ã‚»ãƒ³ã‚µãƒ¼", "ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°", "ã‚¹ãƒãƒ¼ãƒˆãƒ‡ãƒã‚¤ã‚¹", "ç”£æ¥­iot"]
            for kw in key_keywords:
                if kw in title_lower: score += 9
                
        elif category == "cloud":
            popular_keywords = ["aws", "azure", "gcp", "kubernetes", "docker", "ã‚¯ãƒ©ã‚¦ãƒ‰ç§»è¡Œ"]
            for kw in popular_keywords:
                if kw in title_lower: score += 9
        
        elif category == "security":
            tech_keywords = ["ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£", "ã‚¼ãƒ­ãƒˆãƒ©ã‚¹ãƒˆ", "ã‚µã‚¤ãƒãƒ¼æ”»æ’ƒ", "è„†å¼±æ€§", "æš—å·åŒ–"]
            for kw in tech_keywords:
                if kw in title_lower: score += 10
                
        elif category == "dx":
            dx_keywords = ["dx", "ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–", "æ¥­å‹™åŠ¹ç‡åŒ–", "rpa", "ãƒ‡ãƒ¼ã‚¿æ´»ç”¨"]
            for kw in dx_keywords:
                if kw in title_lower: score += 8
        
        return score
    
    # ğŸ”¥ æ”¹å–„: å¼·åŒ–ã•ã‚ŒãŸé‡è¤‡æ’é™¤ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ 
    import re
    from difflib import SequenceMatcher
    
    def normalize_title(title):
        """ ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ­£è¦åŒ–ã—ã¦æ¯”è¼ƒã—ã‚„ã™ãã™ã‚‹ """
        # ç‰¹æ®Šæ–‡å­—ã€å¥èª­ç‚¹ã€æ•°å­—ã‚’é™¤å»
        normalized = re.sub(r'[\u3000-\u303f\uff01-\uff0f\uff1a-\uff20\uff3b-\uff40\uff5b-\uff65]', '', title)
        normalized = re.sub(r'[0-9ï¼-ï¼™]+', '', normalized)  # æ•°å­—ã‚’é™¤å»
        normalized = re.sub(r'\s+', '', normalized)  # ã‚¹ãƒšãƒ¼ã‚¹ã‚’é™¤å»
        return normalized.lower().strip()
    
    def is_similar_content(title1, title2, threshold=0.8):
        """ ã‚¿ã‚¤ãƒˆãƒ«ã®ä¼¼ãŸå†…å®¹ã‚’æ¤œå‡º """
        norm1 = normalize_title(title1)
        norm2 = normalize_title(title2)
        
        if len(norm1) < 10 or len(norm2) < 10:
            return norm1 == norm2
        
        similarity = SequenceMatcher(None, norm1, norm2).ratio()
        return similarity >= threshold
    
    # é‡è¤‡æ’é™¤ã¨ã‚¹ã‚³ã‚¢é †ã‚½ãƒ¼ãƒˆï¼ˆã‚½ãƒ¼ã‚¹åˆ†æ•£è€ƒæ…®ï¼‰
    seen_urls = set()
    seen_normalized_titles = []  # æ­£è¦åŒ–ã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«ã®ãƒªã‚¹ãƒˆ
    unique = []
    source_count = {}  # ã‚½ãƒ¼ã‚¹åˆ¥è¨˜äº‹æ•°ã‚«ã‚¦ãƒ³ãƒˆ
    
    # ã‚¹ã‚³ã‚¢é †ã§ã‚½ãƒ¼ãƒˆ
    filtered.sort(key=calculate_multi_category_score, reverse=True)
    
    for article in filtered:
        # URLé‡è¤‡ãƒã‚§ãƒƒã‚¯
        if article["link"] in seen_urls:
            continue
        
        # ã‚¿ã‚¤ãƒˆãƒ«ã®ä¼¼ãŸå†…å®¹é‡è¤‡ãƒã‚§ãƒƒã‚¯
        current_title = article["title"]
        is_duplicate = False
        for seen_title in seen_normalized_titles:
            if is_similar_content(current_title, seen_title):
                is_duplicate = True
                break
        
        if is_duplicate:
            continue
        
        # ã‚½ãƒ¼ã‚¹åˆ†æ•£ãƒã‚§ãƒƒã‚¯ï¼ˆåŒã˜ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®è¨˜äº‹ãŒå¤šã™ããªã„ã‹ï¼‰
        source_name = article.get("source", "ä¸æ˜")
        current_source_count = source_count.get(source_name, 0)
        max_per_source = max(1, limit // 3)  # ä¸€ã¤ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã®æœ€å¤§è¨˜äº‹æ•°
        
        if current_source_count >= max_per_source:
            # ã“ã®ã‚½ãƒ¼ã‚¹ã‹ã‚‰ã¯ååˆ†è¨˜äº‹ã‚’å–å¾—ã—ãŸã®ã§ã‚¹ã‚­ãƒƒãƒ—
            continue
        
        # è¨˜äº‹ã‚’è¿½åŠ 
        seen_urls.add(article["link"])
        seen_normalized_titles.append(current_title)
        unique.append(article)
        source_count[source_name] = current_source_count + 1
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ¥ã‚«ã‚¦ãƒ³ãƒˆã‚’æ›´æ–°
        category = article.get("category", "other")
        category_counts[category] = category_counts.get(category, 0) + 1
        
        if len(unique) >= limit:
            break

    # ğŸ†• ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒãƒ©ãƒ³ã‚·ãƒ³ã‚°: å„ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‹ã‚‰æœ€ä½1ä»¶ã¯å«ã‚ã‚‹ã‚ˆã†ã«èª¿æ•´
    if len(unique) < limit:
        category_counts = {}
        for article in unique:
            category = article.get("category", "other")
            category_counts[category] = category_counts.get(category, 0) + 1
        
        # ä¸è¶³ã—ã¦ã„ã‚‹ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‹ã‚‰è¨˜äº‹ã‚’è¿½åŠ ï¼ˆSESæ¥­ç•Œã®å…ˆç«¯æŠ€è¡“ï¼‰
        target_categories = ["ai", "iot", "cloud", "security", "dx"]
        for target_category in target_categories:
            if category_counts.get(target_category, 0) == 0 and len(unique) < limit:
                # ã“ã®ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®è¨˜äº‹ã‚’æ¢ã—ã¦è¿½åŠ 
                for article in filtered:
                    if (article.get("category") == target_category and 
                        article["link"] not in seen_urls and
                        len(unique) < limit):
                        
                        unique.append(article)
                        seen_urls.add(article["link"])
                        category_counts[target_category] = 1
                        break

    # çµæœçµ±è¨ˆã‚’ãƒ­ã‚°å‡ºåŠ›
    final_source_stats = {}
    final_category_stats = {}
    for article in unique:
        source = article.get("source", "ä¸æ˜")
        category = article.get("category", "other")
        final_source_stats[source] = final_source_stats.get(source, 0) + 1
        final_category_stats[category] = final_category_stats.get(category, 0) + 1
    
    logging.info(f"Selected {len(unique)} articles from {len(filtered)} filtered articles")
    logging.info(f"æœ€çµ‚é¸æŠã‚½ãƒ¼ã‚¹åˆ†æ•£: {dict(sorted(final_source_stats.items(), key=lambda x: x[1], reverse=True))}")
    logging.info(f"æœ€çµ‚ã‚«ãƒ†ã‚´ãƒªãƒ¼åˆ†æ•£: {dict(sorted(final_category_stats.items(), key=lambda x: x[1], reverse=True))}")
    return unique

def post_to_chatwork(message: str) -> None:
    """ChatWorkã¸ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æŠ•ç¨¿"""
    url = f"https://api.chatwork.com/v2/rooms/{CHATWORK_ROOM_ID}/messages"
    headers = {
        "X-ChatWorkToken": CHATWORK_TOKEN,
        "Content-Type": "application/x-www-form-urlencoded"
    }
    
    data = {"body": "[toall]\n" + message}
    resp = requests.post(url, headers=headers, data=data)
    resp.raise_for_status()

def build_news_message(articles: list[dict]) -> str:
    """SESæ¥­ç•Œå‘ã‘å…ˆç«¯æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä½œæˆ"""
    current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    current_time = datetime.now().strftime("%H:%M")
    
    # ã‚½ãƒ¼ã‚¹çµ±è¨ˆã€ã‚«ãƒ†ã‚´ãƒªãƒ¼çµ±è¨ˆã€Tieræƒ…å ±ã‚’é›†è¨ˆ
    sources = {}
    category_stats = {}
    tier_stats = {}
    
    for article in articles:
        source = article.get("source", "ä¸æ˜")
        category = article.get("category", "other")
        tier = article.get("tier", "additional")
        
        sources[source] = sources.get(source, 0) + 1
        category_stats[category] = category_stats.get(category, 0) + 1
        tier_stats[tier] = tier_stats.get(tier, 0) + 1
    
    message_parts = [
        f"[info][title]ğŸ’¼ é€±é–“SESæŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ - {current_date}[/title]",
        f"ğŸ“… é…ä¿¡æ™‚åˆ»: {current_time} (æ¯é€±æœˆæ›œæ—¥é…ä¿¡)",
        f"ğŸ“Š è¨˜äº‹æ•°: {len(articles)}ä»¶ (å³é¸ãƒ»é‡è¤‡æ’é™¤æ¸ˆ)",
        f"ğŸ“¡ æƒ…å ±æº: {len(sources)}ã‚µã‚¤ãƒˆ (ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆ)",
        f"ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªãƒ¼: {len(category_stats)}ç¨®é¡ (AIãƒ»IoTãƒ»ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»DX)",
        "",
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        ""
    ]
    
    for i, article in enumerate(articles, 1):
        title = article['title']
        if len(title) > 80:
            title = title[:77] + "..."
        
        source = article.get('source', 'ä¸æ˜')
        tier = article.get('tier', 'tier6')
        
        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã”ã¨ã®ã‚¢ã‚¤ã‚³ãƒ³ï¼ˆSESæ¥­ç•Œã®å…ˆç«¯æŠ€è¡“ï¼‰
        category_icons = {
            'ai': 'ğŸ¤–',              # AIãƒ»æ©Ÿæ¢°å­¦ç¿’
            'iot': 'ğŸ“¡',             # IoTãƒ»ã‚»ãƒ³ã‚µãƒ¼
            'cloud': 'â˜ï¸',            # ã‚¯ãƒ©ã‚¦ãƒ‰
            'security': 'ğŸ”’',        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
            'dx': 'ğŸš€'               # DXãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–
        }
        category = article.get('category', 'other')
        category_icon = category_icons.get(category, 'ğŸ“°')
        
        message_parts.extend([
            f"{category_icon} ã€è¨˜äº‹ {i}ã€‘{source} ({category.upper()})",
            f"ğŸ’¡ {title}",
            f"ğŸ”— {article['link']}",
            ""
        ])
    
    # ã‚½ãƒ¼ã‚¹åˆ†æ•£æƒ…å ±ã‚’è¡¨ç¤º
    if len(sources) > 1:
        message_parts.extend([
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            "ğŸ“ˆ æƒ…å ±æºåˆ†æ•£çŠ¶æ³ (é‡è¤‡æ’é™¤ãƒ»ãƒãƒ©ãƒ³ã‚¹èª¿æ•´æ¸ˆ):",
            ""
        ])
        
        sorted_sources = sorted(sources.items(), key=lambda x: x[1], reverse=True)
        for source, count in sorted_sources:
            message_parts.append(f"ã€€â€¢ {source}: {count}ä»¶")
        
        message_parts.extend([
            "",
            "ğŸ·ï¸ ã‚«ãƒ†ã‚´ãƒªåˆ¥åˆ†æ•£:"
        ])
        
        category_names = {
            'ai': 'ğŸ¤– AIãƒ»æ©Ÿæ¢°å­¦ç¿’',
            'iot': 'ğŸ“¡ IoTãƒ»ã‚¨ãƒƒã‚¸ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°', 
            'cloud': 'â˜ï¸ ã‚¯ãƒ©ã‚¦ãƒ‰ï¼ˆAWS/Azure/GCPï¼‰',
            'security': 'ğŸ”’ ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ã‚µã‚¤ãƒãƒ¼å¯¾ç­–',
            'dx': 'ğŸš€ DXãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–æ¨é€²'
        }
        
        for category, count in sorted(category_stats.items(), key=lambda x: x[1], reverse=True):
            category_name = category_names.get(category, f'â“ {category}')
            message_parts.append(f"ã€€â€¢ {category_name}: {count}ä»¶")
        
        message_parts.append("")
    
    message_parts.extend([
        "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
        "âœ¨ SESæ¥­ç•Œã§æ±‚ã‚ã‚‰ã‚Œã‚‹å…ˆç«¯æŠ€è¡“æƒ…å ±ã‚’å³é¸ã—ã¦ãŠå±Šã‘ï¼",
        "ğŸ” é‡è¤‡æ’é™¤ãƒ»ã‚½ãƒ¼ã‚¹åˆ†æ•£ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã«ã‚ˆã‚Šå“è³ªã‚’ç¢ºä¿ã€‚",
        "ğŸ“± æ°—ã«ãªã‚‹è¨˜äº‹ãŒã‚ã‚Œã°ãƒªãƒ³ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã”è¦§ãã ã•ã„ã€‚",
        "ğŸ“… æ¬¡å›é…ä¿¡: æ¥é€±æœˆæ›œæ—¥ã®æœ9æ™‚ã§ã™ã€‚",
        "ğŸ’¼ AIãƒ»IoTãƒ»ã‚¯ãƒ©ã‚¦ãƒ‰ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»DXã®5åˆ†é‡ã‚’ç¶²ç¾…ã€‚",
        "ğŸš€ é«˜å˜ä¾¡æ¡ˆä»¶ç²å¾—ã«å¿…è¦ãªæŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ã‚­ãƒ£ãƒƒãƒã‚¢ãƒƒãƒ—ï¼",
        "[/info]"
    ])
    
    return "\n".join(message_parts)

def build_no_news_message() -> str:
    """è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    current_time = datetime.now().strftime("%H:%M")
    
    return (
        f"[info][title]ğŸ’¼ é€±é–“SESæŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰ - {current_date}[/title]\n"
        f"ğŸ“… é…ä¿¡æ™‚åˆ»: {current_time}\n"
        f"ğŸ“Š è¨˜äº‹æ•°: 0ä»¶\n\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        f"ğŸ” ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ã€‚æœ¬æ—¥ã¯æ–°ã—ã„é–¢é€£è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n"
        f"ğŸ“° æ¥é€±ã¾ãŸæœ€æ–°æƒ…å ±ã‚’ãŠå±Šã‘ã„ãŸã—ã¾ã™ï¼\n\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"[/info]"
    )

def build_error_message() -> str:
    """ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿæ™‚ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"""
    current_date = datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥")
    current_time = datetime.now().strftime("%H:%M")
    
    return (
        f"[info][title]âš ï¸ ã‚·ã‚¹ãƒ†ãƒ é€šçŸ¥ - {current_date}[/title]\n"
        f"ğŸ“… é€šçŸ¥æ™‚åˆ»: {current_time}\n\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
        f"ğŸš¨ SESæŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰é…ä¿¡ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚\n"
        f"ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ã”ç¢ºèªãã ã•ã„ã€‚\n"
        f"ğŸ• æ¬¡å›ã®é…ä¿¡ã‚’ãŠå¾…ã¡ãã ã•ã„ã€‚\n\n"
        f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
        f"[/info]"
    )

def main():
    try:
        news_list = fetch_multi_category_news()
        
        if not news_list:
            logging.warning("å–å¾—ã§ããŸè¨˜äº‹ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
            no_news_msg = build_no_news_message()
            post_to_chatwork(no_news_msg)
            return

        unified_msg = build_news_message(news_list)
        post_to_chatwork(unified_msg)
        
        logging.info(f"SESæ¥­ç•Œå‘ã‘å…ˆç«¯æŠ€è¡“ãƒ‹ãƒ¥ãƒ¼ã‚¹ {len(news_list)}ä»¶ã‚’ä¸€æ‹¬æŠ•ç¨¿ã—ã¾ã—ãŸã€‚")
        
    except Exception as e:
        logging.exception("ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚")
        error_msg = build_error_message()
        try:
            post_to_chatwork(error_msg)
        except:
            logging.error("ã‚¨ãƒ©ãƒ¼é€šçŸ¥ã®æŠ•ç¨¿ã«ã‚‚å¤±æ•—ã—ã¾ã—ãŸã€‚")

if __name__ == "__main__":
    main()
